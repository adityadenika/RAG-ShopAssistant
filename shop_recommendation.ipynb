{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5e11ab",
   "metadata": {},
   "source": [
    "# Shop Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02707e43",
   "metadata": {},
   "source": [
    "Pada Notebook ini akan dibuat Shop Recommendation dengan menggunakan Haystack Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf148d",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "id": "2bd6677b",
   "metadata": {},
   "source": [
    "from haystack import Pipeline, component\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.tools.tool import Tool\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from pymongo import MongoClient\n",
    "from typing import List,Annotated\n",
    "from getpass import getpass\n",
    "import re\n",
    "import json\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0280afb3",
   "metadata": {},
   "source": [
    "import logging\n",
    "from haystack import tracing\n",
    "from haystack.tracing.logging_tracer import LoggingTracer\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.DEBUG)\n",
    "\n",
    "tracing.tracer.is_content_tracing_enabled = True # to enable tracing/logging content (inputs/outputs)\n",
    "tracing.enable_tracing(LoggingTracer(tags_color_strings={\"haystack.component.input\": \"\\x1b[1;31m\", \"haystack.component.name\": \"\\x1b[1;34m\"}))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "895ff6c1",
   "metadata": {},
   "source": [
    "Load OPENAI_API_KEY dan MONGODB_CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f2b4eed",
   "metadata": {},
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Masukkan OpenAI API Key Anda: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9f86014",
   "metadata": {},
   "source": [
    "os.environ[\"MONGO_CONNECTION_STRING\"] = getpass(\"Masukkan MongoDB Connection String Anda: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a786d6e5",
   "metadata": {},
   "source": [
    "Inisialisasi MONGODB ATLAS DOCUMENT STORE dan InMemoryChatMessageStore "
   ]
  },
  {
   "cell_type": "code",
   "id": "cbd12dae",
   "metadata": {},
   "source": [
    "chat_message_store = InMemoryChatMessageStore()\n",
    "document_store = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"products\",\n",
    "    vector_search_index=\"vector_index\",\n",
    "    full_text_search_index=\"search_index\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9824ef3e",
   "metadata": {},
   "source": [
    "## Membuat Paraphraser Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ce63669",
   "metadata": {},
   "source": [
    "class ParaphraserPipeline:\n",
    "    def __init__(self,chat_message_store):\n",
    "        self.memory_retriever = ChatMessageRetriever(chat_message_store)\n",
    "        # self.memory_retriever = memory_retriever\n",
    "        # self.memory_writer = memory_writer\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"prompt_builder\",ChatPromptBuilder(variables=[\"query\",\"memories\"],required_variables=[\"query\", \"memories\"],))\n",
    "        self.pipeline.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))\n",
    "        self.pipeline.add_component(\"memory_retriever\", self.memory_retriever)\n",
    "\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "    \n",
    "    def run(self, query):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\n",
    "                \"You are a helpful assistant that paraphrases user queries based on previous conversations.\"\n",
    "            ),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                Please paraphrase the following query based on the conversation history provided below. If the conversation history is empty, please return the query as is.\n",
    "                history:\n",
    "                {% for memory in memories %}\n",
    "                    {{memory.text}}\n",
    "                {% endfor %}\n",
    "                query: {{query}}\n",
    "                answer:\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        res = self.pipeline.run(\n",
    "            data = {\n",
    "                \"prompt_builder\":{\n",
    "                    \"query\": query,\n",
    "                    \"template\": messages\n",
    "                },\n",
    "                # \"joiner\":{\n",
    "                #     \"values\":  [ChatMessage.from_user(query)]\n",
    "                # }\n",
    "            },\n",
    "            include_outputs_from=[\"generator\"]\n",
    "        )\n",
    "        print(\"Pipeline Input\", query)\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a78b6490",
   "metadata": {},
   "source": [
    "paraprahser_pipeline = ParaphraserPipeline(chat_message_store=chat_message_store)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e89bc126",
   "metadata": {},
   "source": [
    "### Membuat History Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "e8fc386b",
   "metadata": {},
   "source": [
    "class ChatHistoryPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\"prompt_builder\", PromptBuilder(variables=[\"memories\"], required_variables=[\"memories\"], template=\"\"\"\n",
    "        Previous Conversations history:\n",
    "        {% for memory in memories %}\n",
    "            {{memory.text}}\n",
    "        {% endfor %}\n",
    "        \"\"\")\n",
    "        )\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "\n",
    "    def run(self):\n",
    "        res = self.pipeline.run(\n",
    "            data = {},\n",
    "            include_outputs_from=[\"prompt_builder\"]\n",
    "        )\n",
    "\n",
    "        # print(\"Pipeline Input\", res[\"prompt_builder\"][\"prompt\"])\n",
    "        return res[\"prompt_builder\"][\"prompt\"]\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4d5c733",
   "metadata": {},
   "source": [
    "chat_history_pipeline = ChatHistoryPipeline(chat_message_store=chat_message_store)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "979d20e1",
   "metadata": {},
   "source": [
    "## Membuat  Metadata Filter Tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a2281cd",
   "metadata": {},
   "source": [
    "class MongoDBAtlas:\n",
    "    def __init__(self, mongo_connection_string:str):\n",
    "        self.client = MongoClient(mongo_connection_string)\n",
    "        self.db = self.client.depato_store\n",
    "        self.material_collection = self.db.materials\n",
    "        self.category_collection = self.db.categories\n",
    "\n",
    "    def get_materials(self):\n",
    "        return [doc['name'] for doc in self.material_collection.find()]\n",
    "\n",
    "    def get_categories(self):\n",
    "        return [doc['name'] for doc in self.category_collection.find()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "934b1f35",
   "metadata": {},
   "source": [
    "@component\n",
    "class GetMaterials:\n",
    "    def __init__(self):\n",
    "        self.db = MongoDBAtlas(os.environ['MONGO_CONNECTION_STRING'])\n",
    "    \n",
    "    @component.output_types(materials=List[str])\n",
    "    def run(self):\n",
    "        materials = self.db.get_materials()\n",
    "        return {\"materials\": materials}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a24b12e",
   "metadata": {},
   "source": [
    "@component\n",
    "class GetCategories:\n",
    "    def __init__(self):\n",
    "        self.db = MongoDBAtlas(os.environ['MONGO_CONNECTION_STRING'])\n",
    "    \n",
    "    @component.output_types(categories=List[str])\n",
    "    def run(self):\n",
    "        categories = self.db.get_categories()\n",
    "        return {\"categories\": categories}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "004a3ea8",
   "metadata": {},
   "source": [
    "METADATA_FILTER_TEMPLATE = \"\"\"\n",
    "You are a json generator that have a job to generate json based on the input.\n",
    "The return json should be in the format:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\":[\n",
    "        {\"field\": \"meta.category\", \"operator\":\"==\", \"value\": <category>},\n",
    "        {\"field\": \"meta.material\", \"operator\":\"==\", \"value\": <material>},\n",
    "        {\"filed\": \"meta.gender\", \"operator\":\"==\", \"value\" : <male|female|unisex>},\n",
    "        {\"field\": \"meta.price\", \"operator\":<\"<=\"|\">=\"|\"==\">, \"value\": <price>}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "The json key above can be omiitted if the value is not provided in the input, so please make sure to only return the keys that are provided in the input.\n",
    "\n",
    "For the material and category, you can only use the material and category that are provided below:\n",
    "Materials: [ {% for material in materials %} {{ material }} {% if not loop.last %}, {% endif %} {% endfor %} ]\n",
    "\n",
    "Categories: [ {% for category in categories %} {{ category }} {% if not loop.last %}, {% endif %} {% endfor %} ]\n",
    "\n",
    "if the input does not contain any of the keys above, you should return an empty json object like this:\n",
    "```json\n",
    "{}\n",
    "```\n",
    "Sometimes the material and category can be negated, so you should also handle that by using the operator \"!=\" for material and category. \n",
    "\n",
    "Sometimes the material and category is not explicitly mentioned, you should analyze which material and category is the most suitable based on the input, and return the json with the material and category that you think is the most suitable.\n",
    "\n",
    "Nestede conditions are allowed, for nested conditions, you can use \"OR\" and \"AND\" as the operator, and the conditions should be in the \"conditions\" array.\n",
    "\n",
    "if user said the price around some value, please find the price between those value -10 and value +10.\n",
    "\n",
    "The example of the result are expected to be like this:\n",
    "\n",
    "1. Input: \"can you give me a adress with cotton material?\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Cotton\"},\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "2. Input: \"Give me Shirt that is not made of cotton and has a price less than $100\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Tops\"},\n",
    "        {\"field\": \"meta.material\", \"operator\": \"!=\", \"value\": \"Cotton\"},\n",
    "        {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 100}\n",
    "    ]\n",
    "}\n",
    "3. Input: \"I want a dress that is not hot and has a price greater than $50\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"},\n",
    "        {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 50},\n",
    "        {\n",
    "            \"operator\": \"OR\",\n",
    "            \"conditions\": [\n",
    "                {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Cotton\"},\n",
    "                {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Polyester\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "4. Input i want tops that have price between $20 and $50\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Tops\"},\n",
    "        {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\":[\n",
    "                {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 20},\n",
    "                {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 50}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "5. Input: I want the dress price around $50\n",
    "output: \n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"},\n",
    "        {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\":[\n",
    "                {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 40},\n",
    "                {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 60}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "6. Input: {{input}}\n",
    "output:\n",
    "\n",
    "```\n",
    "\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6608b89a",
   "metadata": {},
   "source": [
    "class MetaDataFilterPipeline:\n",
    "    def __init__(self, get_materials, get_categories, template):\n",
    "        self.get_materials = get_materials\n",
    "        self.get_categories = get_categories\n",
    "        self.template = template\n",
    "\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"materials\", GetMaterials())\n",
    "        self.pipeline.add_component(\"categories\", GetCategories())\n",
    "        self.pipeline.add_component(\n",
    "            \"prompt_builder\",\n",
    "            PromptBuilder(\n",
    "                template=self.template,\n",
    "                required_variables=[\"input\", \"materials\", \"categories\"],\n",
    "            )\n",
    "        )\n",
    "        self.pipeline.add_component(\"generator\", OpenAIGenerator(\n",
    "            model=\"gpt-4.1-2025-04-14\",\n",
    "            api_key=Secret.from_token(os.environ['OPENAI_API_KEY'])\n",
    "        ))\n",
    "        self.pipeline.connect(\"materials.materials\", \"prompt_builder.materials\")\n",
    "        self.pipeline.connect(\"categories.categories\", \"prompt_builder.categories\")\n",
    "        self.pipeline.connect(\"prompt_builder\",\"generator\")\n",
    "\n",
    "    def run(self, query: str):\n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                \"prompt_builder\": {\n",
    "                    \"input\": query,\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "        return res[\"generator\"][\"replies\"][0]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "36cfd090",
   "metadata": {},
   "source": [
    "## Data Retrieve and Generate Answer Tools"
   ]
  },
  {
   "cell_type": "code",
   "id": "f105d1ff",
   "metadata": {},
   "source": [
    "class RetrieveAndGenerateAnswerPipeline:\n",
    "    def __init__(self, chat_message_store, document_store):\n",
    "        self.chat_message_store = chat_message_store\n",
    "        self.document_store = document_store\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder())\n",
    "        self.pipeline.add_component(\"retriever\", MongoDBAtlasEmbeddingRetriever(document_store=document_store,top_k=10))\n",
    "        self.pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(variables=[\"query\",\"documents\"],required_variables=[\"query\", \"documents\"]))\n",
    "        self.pipeline.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))\n",
    "        # self.pipeline.add_component(\"chat_message_writer\", ChatMessageWriter(chat_message_store))\n",
    "        # self.pipeline.add_component(\"joiner\", ListJoiner(List[ChatMessage]))\n",
    "        \n",
    "        self.pipeline.connect(\"embedder\", \"retriever\")\n",
    "        self.pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "        # self.pipeline.connect(\"generator.replies\", \"joiner\")\n",
    "        # self.pipeline.connect(\"joiner\", \"chat_message_writer\")\n",
    "\n",
    "    def run(self, query: str, filter: dict = {}):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\n",
    "                \"You are a helpful shop assistant that will give products recommendation based on user query and metadata filtering. \"\n",
    "            ),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                Your task is to generate a list of products that best match the query.\n",
    "\n",
    "                The output should be a list of products in the following format:\n",
    "\n",
    "                <summary_of_query>\n",
    "                <index>. <product_name> \n",
    "                Price: <product_price>\n",
    "                Material: <product_material>\n",
    "                Category: <product_category>\n",
    "                Brand: <product_brand>\n",
    "                Recommendation: <product_recommendation>\n",
    "\n",
    "                From the format above, you should pay attention to the following:\n",
    "                1. <summary_of_query> should be a short summary of the query.\n",
    "                2. <index> should be a number starting from 1.\n",
    "                3. <product_name> should be the name of the product, this product name can be found from the product_name field.\n",
    "                4. <product_price> should be the price of the product, this product price can be found from the product_price field.\n",
    "                5. <product_material> should be the material of the product, this product material can be found from the product_material field.\n",
    "                6. <product_category> should be the category of the product, this product category can be found from the product_category field.\n",
    "                7. <product_brand> should be the brand of the product, this product brand can be found from the product_brand field.\n",
    "                8. <product_recommendation> should be the recommendation of the product, you should give a recommendation why this product is recommended, please pay attentation to the product_content field. \n",
    "\n",
    "\n",
    "                You should only return the list of products that best match the query, do not return any other information.\n",
    "\n",
    "                if there is no matching product below, please say so.\n",
    "\n",
    "                The query is: {{query}}\n",
    "                {% if documents|length > 0 %}\n",
    "                the products are:\n",
    "                {% for product in documents %}\n",
    "                ===========================================================\n",
    "                {{loop.index}}. product_name: {{ product.meta.title }}\n",
    "                product_price: {{ product.meta.price }}\n",
    "                product_material: {{ product.meta.material }}\n",
    "                product_category: {{ product.meta.category }}\n",
    "                product_brand: {{ product.meta.brand }}\n",
    "                product_content: {{ product.content}}\n",
    "                {% endfor %}\n",
    "\n",
    "                ===========================================================\n",
    "                {% else %}\n",
    "                There is no matching product.\n",
    "                {% endif %}\n",
    "\n",
    "                Answer:\n",
    "\n",
    "                \"\"\"\n",
    "            )\n",
    "        ]\n",
    "        res = self.pipeline.run(\n",
    "            data={\n",
    "                \"embedder\":{\n",
    "                    \"text\": query,\n",
    "                },\n",
    "                \"retriever\":{\n",
    "                    \"filters\":filter\n",
    "                },\n",
    "               \"prompt_builder\":{\n",
    "                   \"query\": query,\n",
    "                   \"template\": messages\n",
    "               },\n",
    "\n",
    "            },\n",
    "            include_outputs_from=[\"generator\", \"prompt_builder\"]\n",
    "        )\n",
    "        print(res[\"prompt_builder\"][\"prompt\"])\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0edd800b",
   "metadata": {},
   "source": [
    "retrieve_and_generate_pipeline = RetrieveAndGenerateAnswerPipeline(chat_message_store=chat_message_store, document_store=document_store)\n",
    "metadata_filter_pipeline = MetaDataFilterPipeline(\n",
    "    get_materials=GetMaterials(),\n",
    "    get_categories=GetCategories(),\n",
    "    template=METADATA_FILTER_TEMPLATE\n",
    ")\n",
    "\n",
    "def retrieve_and_generate(query: Annotated[str, \"User query\"]):\n",
    "    \"\"\"\n",
    "    This tool retrieves products based on user query and generates an answer.\n",
    "    \"\"\"\n",
    "    pharaprased_query = paraprahser_pipeline.run(query)\n",
    "    result = metadata_filter_pipeline.run(pharaprased_query)\n",
    "    data = {}\n",
    "    try:\n",
    "        json_match = re.search(r'```json\\n(.*?)\\n```', result, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)\n",
    "            data = json.loads(json_str)\n",
    "        else:\n",
    "            logging.error(\"No JSON found in the result.\")\n",
    "            data = {}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing JSON from result: {e}\")\n",
    "        data = {}\n",
    "    \n",
    "\n",
    "    return retrieve_and_generate_pipeline.run(pharaprased_query,data)\n",
    "\n",
    "retrieve_and_generate_tool = Tool(\n",
    "    name=\"retrieve_and_generate_recommendation\",\n",
    "    description=\"Use this tool to create metadata filter, retrieve products based on user query, and generate an answer.\",\n",
    "    function=retrieve_and_generate,\n",
    "    parameters= {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user query to retrieve products and generate an answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "008a7b73",
   "metadata": {},
   "source": [
    "### AGENT"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d65343f",
   "metadata": {},
   "source": [
    "agent = Agent(\n",
    "    chat_generator = OpenAIChatGenerator(model=\"gpt-4.1-2025-04-14\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])),\n",
    "    tools=[retrieve_and_generate_tool],\n",
    "    system_prompt=\"\"\"\n",
    "    You are a helpful shop assistant that provides product recommendations.\n",
    "    \n",
    "    DECISION LOGIC:\n",
    "    1. If the user asks general questions (greetings, general info), respond directly without using tools.\n",
    "    2. If the user asks about products, please analyze the question first. If you got enough information, you can use the retrieve_and_generate tool directly. The information of product that you can receive are material, price, and category. Please analyze it based on the conversation history and the user's query.\n",
    "    \n",
    "    WORKFLOW:\n",
    "    Prepare a tool call if needed, otherwise use your knowledge to respond to the user.\n",
    "    If the invocation of a tool requires the result of another tool, prepare only one call at a time.\n",
    "\n",
    "    Each time you receive the result of a tool call, ask yourself: \"Am I done with the task?\".\n",
    "    If not and you need to invoke another tool, prepare the next tool call.\n",
    "    If you are done, respond with just the final result.\n",
    "\n",
    "    If the user ask outside the context of product recommendations, politely inform them that you can only assist with that.\n",
    "\n",
    "    \"\"\",\n",
    "    exit_conditions=[\"text\"],\n",
    "    max_agent_steps= 20,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d737fe8",
   "metadata": {},
   "source": [
    "agent.warm_up()\n",
    "chat_message_writer = ChatMessageWriter(chat_message_store)\n",
    "while True:\n",
    "    query = input(\"Masukkan query: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    history = chat_history_pipeline.run()\n",
    "    messages = [ChatMessage.from_system(history),ChatMessage.from_user(query)]\n",
    "    chat_message_writer.run([ChatMessage.from_user(query)])\n",
    "    response = agent.run(messages=messages)\n",
    "    response_text = response[\"messages\"][-1].text\n",
    "\n",
    "    messages_save = [\n",
    "        ChatMessage.from_assistant(response_text)\n",
    "    ]\n",
    "    chat_message_writer.run(messages_save)\n",
    "    print(f\"Response: {response_text}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14b422e6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shop_recommendation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
